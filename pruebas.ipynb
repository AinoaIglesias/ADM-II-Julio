{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f380b805",
   "metadata": {},
   "source": [
    "Este cuaderno sirve para probar el framework como un cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1af3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------- IMPORTACIONES\n",
    "#-----------------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "from framework.datasource import CSVDataSource\n",
    "from framework.processor  import DataProcessor\n",
    "from framework.cleaner    import Cleaner, TypeOnlyCleaner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9290f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------- IDataSource\n",
    "#-----------------------------------------------\n",
    "DATA_PATH = \"datasets/madrid_2001_2018_calidad_aire.csv\"\n",
    "\n",
    "csv_source = CSVDataSource(DATA_PATH)\n",
    "df = csv_source.load()\n",
    "\n",
    "# Comprobar si cargó el dataset\n",
    "#print(\"Primeras filas:\")\n",
    "#display(df.head())\n",
    "#print(\"\\nShape:\", df.shape)\n",
    "#print(\"\\nTipos de dato por columna:\")\n",
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed620ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape via processor: (3808224, 19)\n",
      "Dtypes via processor: {'date': 'object', 'BEN': 'float64', 'CH4': 'float64', 'CO': 'float64', 'EBE': 'float64', 'MXY': 'float64', 'NMHC': 'float64', 'NO': 'float64', 'NO_2': 'float64', 'NOx': 'float64', 'OXY': 'float64', 'O_3': 'float64', 'PM10': 'float64', 'PM25': 'float64', 'PXY': 'float64', 'SO_2': 'float64', 'TCH': 'float64', 'TOL': 'float64', 'station': 'int64'}\n",
      "Columns via processor: ['date', 'BEN', 'CH4', 'CO', 'EBE', 'MXY', 'NMHC', 'NO', 'NO_2', 'NOx', 'OXY', 'O_3', 'PM10', 'PM25', 'PXY', 'SO_2', 'TCH', 'TOL', 'station']\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------- IDataSource\n",
    "#-----------------------------------------------\n",
    "processor = DataProcessor()\n",
    "\n",
    "# tupla numero registros y columnas\n",
    "print(\"Shape via processor:\", processor.get_shape(df))\n",
    "# diccionario columna y tipo dato\n",
    "print(\"Dtypes via processor:\", processor.get_dtypes(df))\n",
    "# lista con columnas\n",
    "print(\"Columns via processor:\", processor.get_columns(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863c28eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "[\"Columna 'station' convertida a tipo category.\"]\n"
     ]
    }
   ],
   "source": [
    "# pasar `station` a categoría\n",
    "caster = TypeOnlyCleaner(dtype_map={\"station\": \"category\"})\n",
    "df2 = caster.clean(df)\n",
    "\n",
    "# Compruebo\n",
    "print(df2.dtypes[\"station\"])          # category\n",
    "print(df2.attrs[\"cleaning_log\"])      # mensajes de conversión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230315cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default Cleaner -> shape: (3808224, 9)\n",
      "Log (primeras 5 entradas):\n",
      " - Columna 'date' convertida a datetime.\n",
      " - 'date' imputada con 'Desconocido'.\n",
      " - Columna 'BEN' eliminada (> 73% nulos).\n",
      " - Columna 'CH4' eliminada (> 100% nulos).\n",
      " - 'CO' imputada con media.\n",
      " - Columna 'EBE' eliminada (> 74% nulos).\n",
      " - Columna 'MXY' eliminada (> 92% nulos).\n",
      " - Columna 'NMHC' eliminada (> 72% nulos).\n",
      " - 'NO' imputada con media.\n",
      " - 'NO_2' imputada con media.\n",
      " - 'NOx' imputada con media.\n",
      " - Columna 'OXY' eliminada (> 92% nulos).\n",
      " - 'O_3' imputada con media.\n",
      " - 'PM10' imputada con media.\n",
      " - Columna 'PM25' eliminada (> 79% nulos).\n",
      " - Columna 'PXY' eliminada (> 92% nulos).\n",
      " - 'SO_2' imputada con media.\n",
      " - Columna 'TCH' eliminada (> 71% nulos).\n",
      " - Columna 'TOL' eliminada (> 73% nulos).\n",
      " - 'station' imputada con 'Desconocido'.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------- ICleaner\n",
    "\n",
    "#copias para test\n",
    "df_a = df2\n",
    "df_b = df2\n",
    "df_c = df2\n",
    "df_d = df2\n",
    "\n",
    "# cleaner por defecto: elimina columnas con mas del 70% nulos, imputa media y con Desconocido, elimina constantes y vacias, y convierte fechas\n",
    "cleaner_default = Cleaner()\n",
    "df_cleaned = cleaner_default.clean(df2)\n",
    "print(\"\\nDefault Cleaner -> shape:\", df_cleaned.shape)\n",
    "print(\"Log (primeras 5 entradas):\")\n",
    "for line in df_cleaned.attrs[\"cleaning_log\"][:100]:\n",
    "    print(\" -\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9426aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "strategy_numeric='drop' -> shape: (146924, 14)\n",
      "Log (primeras 5 entradas):\n",
      " - Columna 'date' convertida a datetime.\n",
      " - 'date' imputada con 'Desconocido'.\n",
      " - Columna 'BEN' eliminada (> 73% nulos).\n",
      " - Columna 'CH4' eliminada (> 100% nulos).\n",
      " - Dropped 1157212 filas con nulos en 'CO'.\n",
      " - Columna 'EBE' eliminada (> 73% nulos).\n",
      " - Columna 'MXY' eliminada (> 88% nulos).\n",
      " - Dropped 1815336 filas con nulos en 'NMHC'.\n",
      " - Columna 'NO' eliminada (> 87% nulos).\n",
      " - Dropped 1277 filas con nulos en 'NO_2'.\n",
      " - Dropped 99308 filas con nulos en 'NOx'.\n",
      " - Dropped 462372 filas con nulos en 'OXY'.\n",
      " - Dropped 1292 filas con nulos en 'O_3'.\n",
      " - Dropped 518 filas con nulos en 'PM10'.\n",
      " - Dropped 123203 filas con nulos en 'PM25'.\n",
      " - Dropped 61 filas con nulos en 'PXY'.\n",
      " - Dropped 32 filas con nulos en 'SO_2'.\n",
      " - Dropped 364 filas con nulos en 'TCH'.\n",
      " - Dropped 325 filas con nulos en 'TOL'.\n",
      " - 'station' imputada con 'Desconocido'.\n"
     ]
    }
   ],
   "source": [
    "# strategy_numeric='drop': elimina columnas con mas del 70% nulos, elimina registros con numericos nulos e imputa con desconocido, elimina constantes y vacias, y convierte fechas\n",
    "cleaner_drop_num = Cleaner(strategy_numeric=\"drop\")\n",
    "df_cleanA = cleaner_drop_num.clean(df_a)\n",
    "print(\"\\nstrategy_numeric='drop' -> shape:\", df_cleanA.shape)\n",
    "print(\"Log (primeras 5 entradas):\")\n",
    "for line in df_cleanA.attrs[\"cleaning_log\"][:100]:\n",
    "    print(\" -\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b9aa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "strategy_categorical='drop' -> shape: (3808224, 9)\n",
      "Log (primeras 5 entradas):\n",
      " - Columna 'date' convertida a datetime.\n",
      " - Dropped 0 filas con nulos en 'date'.\n",
      " - Columna 'BEN' eliminada (> 73% nulos).\n",
      " - Columna 'CH4' eliminada (> 100% nulos).\n",
      " - 'CO' imputada con media.\n",
      " - Columna 'EBE' eliminada (> 74% nulos).\n",
      " - Columna 'MXY' eliminada (> 92% nulos).\n",
      " - Columna 'NMHC' eliminada (> 72% nulos).\n",
      " - 'NO' imputada con media.\n",
      " - 'NO_2' imputada con media.\n",
      " - 'NOx' imputada con media.\n",
      " - Columna 'OXY' eliminada (> 92% nulos).\n",
      " - 'O_3' imputada con media.\n",
      " - 'PM10' imputada con media.\n",
      " - Columna 'PM25' eliminada (> 79% nulos).\n",
      " - Columna 'PXY' eliminada (> 92% nulos).\n",
      " - 'SO_2' imputada con media.\n",
      " - Columna 'TCH' eliminada (> 71% nulos).\n",
      " - Columna 'TOL' eliminada (> 73% nulos).\n",
      " - Dropped 0 filas con nulos en 'station'.\n"
     ]
    }
   ],
   "source": [
    "# strategy_categorical='drop': elimina columnas con mas del 70% nulos, imputa media y elimina regostrso categoricos con nulos, elimina constantes y vacias, y convierte fechas\n",
    "cleaner_drop_cat = Cleaner(strategy_categorical=\"drop\")\n",
    "df_cleanB = cleaner_drop_cat.clean(df_b)\n",
    "print(\"\\nstrategy_categorical='drop' -> shape:\", df_cleanB.shape)\n",
    "print(\"Log (primeras 5 entradas):\")\n",
    "for line in df_cleanB.attrs[\"cleaning_log\"][:100]:\n",
    "    print(\" -\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb13ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "drop_empty_const=False -> shape: (3808224, 9)\n",
      "Log (primeras 5 entradas):\n",
      " - Columna 'date' convertida a datetime.\n",
      " - 'date' imputada con 'Desconocido'.\n",
      " - Columna 'BEN' eliminada (> 73% nulos).\n",
      " - Columna 'CH4' eliminada (> 100% nulos).\n",
      " - 'CO' imputada con media.\n",
      " - Columna 'EBE' eliminada (> 74% nulos).\n",
      " - Columna 'MXY' eliminada (> 92% nulos).\n",
      " - Columna 'NMHC' eliminada (> 72% nulos).\n",
      " - 'NO' imputada con media.\n",
      " - 'NO_2' imputada con media.\n",
      " - 'NOx' imputada con media.\n",
      " - Columna 'OXY' eliminada (> 92% nulos).\n",
      " - 'O_3' imputada con media.\n",
      " - 'PM10' imputada con media.\n",
      " - Columna 'PM25' eliminada (> 79% nulos).\n",
      " - Columna 'PXY' eliminada (> 92% nulos).\n",
      " - 'SO_2' imputada con media.\n",
      " - Columna 'TCH' eliminada (> 71% nulos).\n",
      " - Columna 'TOL' eliminada (> 73% nulos).\n",
      " - 'station' imputada con 'Desconocido'.\n"
     ]
    }
   ],
   "source": [
    "# drop_empty_const=False: elimina columnas con mas del 70% nulos, imputa media y con Desconocido, NO elimina constantes y vacias, y convierte fechas\n",
    "cleaner_no_drop = Cleaner(drop_empty_const=False)\n",
    "df_cleanC = cleaner_no_drop.clean(df_c)\n",
    "print(\"\\ndrop_empty_const=False -> shape:\", df_cleanC.shape)\n",
    "print(\"Log (primeras 5 entradas):\")\n",
    "for line in df_cleanC.attrs[\"cleaning_log\"][:100]:\n",
    "    print(\" -\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5150af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "null_threshold=0.3 -> shape: (3808224, 6)\n",
      "Log (primeras 5 entradas):\n",
      " - Columna 'date' convertida a datetime.\n",
      " - 'date' imputada con 'Desconocido'.\n",
      " - Columna 'BEN' eliminada (> 73% nulos).\n",
      " - Columna 'CH4' eliminada (> 100% nulos).\n",
      " - Columna 'CO' eliminada (> 30% nulos).\n",
      " - Columna 'EBE' eliminada (> 74% nulos).\n",
      " - Columna 'MXY' eliminada (> 92% nulos).\n",
      " - Columna 'NMHC' eliminada (> 72% nulos).\n",
      " - Columna 'NO' eliminada (> 60% nulos).\n",
      " - 'NO_2' imputada con media.\n",
      " - Columna 'NOx' eliminada (> 38% nulos).\n",
      " - Columna 'OXY' eliminada (> 92% nulos).\n",
      " - 'O_3' imputada con media.\n",
      " - 'PM10' imputada con media.\n",
      " - Columna 'PM25' eliminada (> 79% nulos).\n",
      " - Columna 'PXY' eliminada (> 92% nulos).\n",
      " - 'SO_2' imputada con media.\n",
      " - Columna 'TCH' eliminada (> 71% nulos).\n",
      " - Columna 'TOL' eliminada (> 73% nulos).\n",
      " - 'station' imputada con 'Desconocido'.\n"
     ]
    }
   ],
   "source": [
    "# Umbral de nulos más estricto (null_threshold=0.3): elimina columnas con mas del 30% nulos, imputa media y con Desconocido, elimina constantes y vacias, y convierte fechas\n",
    "cleaner_strict = Cleaner(null_threshold=0.3)\n",
    "df_cleanD = cleaner_strict.clean(df_d)\n",
    "print(\"\\nnull_threshold=0.3 -> shape:\", df_cleanD.shape)\n",
    "print(\"Log (primeras 5 entradas):\")\n",
    "for line in df_cleanD.attrs[\"cleaning_log\"][:100]:\n",
    "    print(\" -\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49620823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape via processor: (3808224, 9)\n",
      "Dtypes via processor: {'date': 'datetime64[ns]', 'CO': 'float64', 'NO': 'float64', 'NO_2': 'float64', 'NOx': 'float64', 'O_3': 'float64', 'PM10': 'float64', 'SO_2': 'float64', 'station': 'category'}\n",
      "Columns via processor: ['date', 'CO', 'NO', 'NO_2', 'NOx', 'O_3', 'PM10', 'SO_2', 'station']\n"
     ]
    }
   ],
   "source": [
    "# tupla numero registros y columnas\n",
    "print(\"Shape via processor:\", processor.get_shape(df_cleaned))\n",
    "# diccionario columna y tipo dato\n",
    "print(\"Dtypes via processor:\", processor.get_dtypes(df_cleaned))\n",
    "# lista con columnas\n",
    "print(\"Columns via processor:\", processor.get_columns(df_cleaned))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
